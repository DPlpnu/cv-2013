# -*- coding: utf-8 -*-
"""cv_lab3_Alchuk.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oNcaJ8PUxwldi9NG9HtXKZKxEqXPK5Xg

Побудувати CNN на основі LeNet-5 для класифікації зображень на основі  датасету fashion-mnist. 
Зробити налаштування моделі для досягнення необхідної точностіНа базі  Siamese networks побудувати систему для пошуку подібних зображень в  датасеті fashion-mnist. Візуалізувати отримані результати t-SNE.
"""

import numpy as np 
import tensorflow as tf
import os 
import pandas as pd 
import keras
from keras.preprocessing.image import ImageDataGenerator 
from keras.utils.np_utils import to_categorical 
from sklearn.model_selection import train_test_split 
import matplotlib.pyplot as plt
from keras.layers import concatenate
from keras.models import Model 
from keras.layers import Input, Conv2D, BatchNormalization, MaxPool2D, Activation, Flatten, Dense, Dropout

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()

x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255. 
x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255. 
y_train = y_train.astype('int') 
y_test = y_test.astype('int') 

train_groups = [x_train[np.where(y_train==i)[0]] for i in np.unique(y_train)] 
test_groups = [x_test[np.where(y_test==i)[0]] for i in np.unique(y_train)] 
print('train groups:', [x.shape[0] for x in train_groups]) 
print('test groups:', [x.shape[0] for x in test_groups])

lenet_5_model = lenet_5_model = keras.models.Sequential([
    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation='tanh', input_shape=(28,28,1), padding='same'), #C1
    keras.layers.AveragePooling2D(), #S2
    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='tanh', padding='valid'), #C3
    keras.layers.AveragePooling2D(), #S4
    keras.layers.Conv2D(120, kernel_size=5, strides=1, activation='tanh', padding='valid'), #C5
    keras.layers.Flatten(), #Flatten    
    keras.layers.Dense(84, activation='tanh'), #F6
    keras.layers.Dense(10, activation='softmax') #Output layer
])

lenet_5_model.summary()

lenet_5_model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
lenet_5_model.fit(x_train, y_train, batch_size=128, epochs=10, validation_split=0.1)

img_a_in = Input(shape = x_train.shape[1:], name = 'ImageA_Input') 
img_b_in = Input(shape = x_train.shape[1:], name = 'ImageB_Input') 
img_a_feat = lenet_5_model(img_a_in) 
img_b_feat = lenet_5_model(img_b_in) 

features = concatenate([img_a_feat, img_b_feat], name = 'features')
features = tf.keras.layers.Dense(16, activation='relu')(features)
features = tf.keras.layers.BatchNormalization()(features)
features = tf.keras.layers.Activation('relu')(features)
features = tf.keras.layers.Dense(4, activation='relu')(features)
features = tf.keras.layers.BatchNormalization()(features)
features = tf.keras.layers.Activation('relu')(features)
features = tf.keras.layers.Dense(1, activation='sigmoid')(features)

siamese_model = tf.keras.models.Model(inputs = [img_a_feat, img_b_feat], outputs = [features], name = 'Siamese_model')
siamese_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['mae'])
siamese_model.summary()

siamese_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['mae'])

def gen_random_batch(in_groups, batch_halfsize = 8):
    out_img_a, out_img_b, out_score = [], [], []
    all_groups = list(range(len(in_groups)))
    for match_group in [True, False]:
        group_idx = np.random.choice(all_groups, size = batch_halfsize)
        out_img_a += [in_groups[c_idx][np.random.choice(range(in_groups[c_idx].shape[0]))] for c_idx in group_idx]
        if match_group:
            b_group_idx = group_idx
            out_score += [1] * batch_halfsize
        else:
            # anything but the same group
            non_group_idx = [np.random.choice([i for i in all_groups if i != c_idx]) for c_idx in group_idx]
            b_group_idx = non_group_idx
            out_score += [0]*batch_halfsize

        out_img_b += [in_groups[c_idx][np.random.choice(range(in_groups[c_idx].shape[0]))] for c_idx in b_group_idx]
    return np.stack(out_img_a,0), np.stack(out_img_b,0), np.stack(out_score,0)

def show_model_output(nb_examples = 3): 
 pv_a, pv_b, pv_sim = gen_random_batch(test_groups, nb_examples)  
 pred_sim = siamese_model.predict([lenet_5_model.predict(pv_a), lenet_5_model.predict(pv_b)]) 
 fig, m_axs = plt.subplots(2, pv_a.shape[0], figsize = (12, 6))  
 for c_a, c_b, c_d, p_d, (ax1, ax2) in zip(pv_a, pv_b, pv_sim, pred_sim, m_axs.T): 
  ax1.imshow(c_a[:,:,0]) 
  ax1.set_title('Image A\n Actual: %3.0f%%' % (100*c_d))  
  ax1.axis('off') 
  ax2.imshow(c_b[:,:,0]) 
  ax2.set_title('Image B\n Predicted: %3.0f%%' % (100*p_d))  
  ax2.axis('off') 
 return fig

def siam_gen(in_groups, batch_size = 32): 
 while True: 
  pv_a, pv_b, pv_sim = gen_random_batch(train_groups, batch_size//2)  
  yield [lenet_5_model.predict(pv_a), lenet_5_model.predict(pv_b)], pv_sim 

print(32//2)

valid_sim.shape

lenet_5_model.predict(valid_a).shape



valid_a, valid_b, valid_sim = gen_random_batch(test_groups, 1024) 
loss_history = siamese_model.fit(
    siam_gen(train_groups),  
    steps_per_epoch = 500, 
    validation_data=([lenet_5_model.predict(valid_a), lenet_5_model.predict(valid_b)],
    valid_sim), 
    epochs = 4,  
    verbose = True
    )

_ = show_model_output()

x_test_features = lenet_5_model.predict(x_test, verbose = True, batch_size=128) 
from sklearn.manifold import TSNE 
tsne_obj = TSNE(n_components=2, 
 init='pca', 
 random_state=101, 
 method='barnes_hut', 
 n_iter=500, 
 verbose=2) 
tsne_features = tsne_obj.fit_transform(x_test_features)

obj_categories = [  
                    'T-shirt/top','Trouser','Pullover','Dress',
                    'Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot'
                 ]
colors = plt.cm.rainbow(np.linspace(0, 1, 10))
plt.figure(figsize=(10, 10))

for c_group, (c_color, c_label) in enumerate(zip(colors, obj_categories)):
    plt.scatter(tsne_features[np.where(y_test == c_group), 0],
        tsne_features[np.where(y_test == c_group), 1],
        marker='o',
        color=c_color,
        linewidth=1,
        alpha=0.8,
        label=c_label)
plt.xlabel('Dimension 1')
plt.ylabel('Dimension 2')
plt.title('t-SNE on Testing Samples')
plt.legend(loc='best')
plt.savefig('clothes-dist.png')
plt.show(block=False)
